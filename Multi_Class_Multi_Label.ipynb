{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majetikalyan007/ML-algorithms/blob/main/Multi_Class_Multi_Label.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmWkftmpGOiT",
        "outputId": "9e7554ee-07e3-4a7a-fb15-a43fafbdbb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Multi-Class Classification Example\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target  # labels: 0,1,2\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = LogisticRegression(max_iter=200)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Label Classification Example\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Create synthetic dataset\n",
        "X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=5, n_labels=2, random_state=42)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Multi-label classifier (One-vs-Rest strategy)\n",
        "clf = MultiOutputClassifier(LogisticRegression(max_iter=200))\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Sample Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30t-mivKGrZB",
        "outputId": "820341ec-56dc-4347-9dd3-896650c464fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Accuracy: 0.425\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.64      0.70        66\n",
            "           1       0.80      0.74      0.77       102\n",
            "           2       0.87      0.78      0.82       101\n",
            "           3       0.74      0.70      0.72        71\n",
            "           4       0.67      0.49      0.56        37\n",
            "\n",
            "   micro avg       0.79      0.70      0.74       377\n",
            "   macro avg       0.77      0.67      0.71       377\n",
            "weighted avg       0.79      0.70      0.74       377\n",
            " samples avg       0.77      0.71      0.70       377\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==== Dataset (Iris) ====\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)   # long for CrossEntropyLoss\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# ==== Model ====\n",
        "class MultiClassNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MultiClassNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))  # logits\n",
        "\n",
        "model = MultiClassNN(input_dim=4, hidden_dim=16, output_dim=3)\n",
        "\n",
        "# ==== Loss & Optimizer ====\n",
        "criterion = nn.CrossEntropyLoss()  # multi-class\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# ==== Training ====\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# ==== Evaluation ====\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    acc = (preds == y_test).float().mean()\n",
        "    print(\"Test Accuracy:\", acc.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlRDZjUMGuGa",
        "outputId": "827053b8-73b8-42d2-8edc-ebbb9e1a2504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.4268\n",
            "Epoch 40, Loss: 0.2503\n",
            "Epoch 60, Loss: 0.1423\n",
            "Epoch 80, Loss: 0.0918\n",
            "Epoch 100, Loss: 0.0725\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==== Dataset (Synthetic) ====\n",
        "X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=5, n_labels=2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)  # float for BCE\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# ==== Model ====\n",
        "class MultiLabelNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MultiLabelNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))  # logits\n",
        "\n",
        "model = MultiLabelNN(input_dim=20, hidden_dim=32, output_dim=5)\n",
        "\n",
        "# ==== Loss & Optimizer ====\n",
        "criterion = nn.BCEWithLogitsLoss()  # multi-label\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# ==== Training ====\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# ==== Evaluation ====\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    preds = (torch.sigmoid(outputs) > 0.5).float()  # thresholding\n",
        "    acc = (preds == y_test).float().mean()\n",
        "    print(\"Test Accuracy:\", acc.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giBV4KVuHKVa",
        "outputId": "56f6feb2-4f9c-4e6a-ee69-bc48bdd0f24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.4976\n",
            "Epoch 20, Loss: 0.4226\n",
            "Epoch 30, Loss: 0.3756\n",
            "Epoch 40, Loss: 0.3529\n",
            "Epoch 50, Loss: 0.3348\n",
            "Test Accuracy: 0.828000009059906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Label k-NN (Synthetic Dataset)\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# ==== Step 1: Generate dataset ====\n",
        "X, y = make_multilabel_classification(n_samples=1000, n_features=20,\n",
        "                                      n_classes=5, n_labels=2, random_state=42)\n",
        "\n",
        "# ==== Step 2: Train-Test Split ====\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ==== Step 3: Feature Scaling ====\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ==== Step 4: Multi-label k-NN Model ====\n",
        "k = 5\n",
        "base_knn = KNeighborsClassifier(n_neighbors=k)\n",
        "multi_knn = MultiOutputClassifier(base_knn)\n",
        "multi_knn.fit(X_train, y_train)\n",
        "\n",
        "# ==== Step 5: Predictions ====\n",
        "y_pred = multi_knn.predict(X_test)\n",
        "\n",
        "# ==== Step 6: Evaluation ====\n",
        "print(\"\\nMulti-Label k-NN (Synthetic Dataset)\")\n",
        "print(\"Sample Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K2WSypuHWFK",
        "outputId": "e57dfd6a-62db-48f3-970d-e8f3aef1738e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Label k-NN (Synthetic Dataset)\n",
            "Sample Accuracy: 0.44\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.59      0.64       106\n",
            "           1       0.77      0.86      0.81       160\n",
            "           2       0.85      0.77      0.81       151\n",
            "           3       0.68      0.68      0.68       111\n",
            "           4       0.62      0.25      0.36        51\n",
            "\n",
            "   micro avg       0.76      0.70      0.73       579\n",
            "   macro avg       0.72      0.63      0.66       579\n",
            "weighted avg       0.75      0.70      0.72       579\n",
            " samples avg       0.77      0.70      0.70       579\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0fsungtHH6lM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}