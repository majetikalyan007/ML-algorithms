{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWh5ano5Hah/UA3f38s2RV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majetikalyan007/ML-algorithms/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgt6-UrRvUuI"
      },
      "outputs": [],
      "source": [
        "from math import log2\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, attribute=None, threshold=None, is_leaf=False, prediction=None):\n",
        "        # attribute: attribute name to split on (None for leaf)\n",
        "        # threshold: for numeric attributes, the split threshold (<= goes left)\n",
        "        self.attribute = attribute\n",
        "        self.threshold = threshold\n",
        "        self.children = {}  # for categorical: value -> Node; for numeric: 'le' and 'gt'\n",
        "        self.is_leaf = is_leaf\n",
        "        self.prediction = prediction\n",
        "\n",
        "    def add_child(self, key, node):\n",
        "        self.children[key] = node\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.is_leaf:\n",
        "            return f\"Leaf({self.prediction})\"\n",
        "        if self.threshold is None:\n",
        "            return f\"Node({self.attribute})\"\n",
        "        return f\"Node({self.attribute} <= {self.threshold})\"\n",
        "\n",
        "# --- Utility functions ---\n",
        "\n",
        "def entropy(labels):\n",
        "    total = len(labels)\n",
        "    if total == 0:\n",
        "        return 0\n",
        "    counts = Counter(labels)\n",
        "    ent = 0.0\n",
        "    for c in counts.values():\n",
        "        p = c / total\n",
        "        ent -= p * log2(p)\n",
        "    return ent\n",
        "\n",
        "def partition(dataset, attribute):\n",
        "    \"\"\"Return mapping from attribute value (or 'le'/'gt' for numeric) to subset of dataset rows.\"\"\"\n",
        "    # detect numeric vs categorical by checking the type of the first non-none value\n",
        "    for row in dataset:\n",
        "        if attribute in row and row[attribute] is not None:\n",
        "            first_val = row[attribute]\n",
        "            break\n",
        "    else:\n",
        "        # attribute missing in all rows\n",
        "        return {}\n",
        "\n",
        "    if isinstance(first_val, (int, float)):\n",
        "        # numeric: split on median\n",
        "        vals = [row[attribute] for row in dataset if attribute in row]\n",
        "        thresh = sorted(vals)[len(vals)//2]\n",
        "        parts = {'le': [], 'gt': []}\n",
        "        for row in dataset:\n",
        "            if attribute not in row or row[attribute] is None:\n",
        "                # treat missing as separate bucket\n",
        "                parts.setdefault('missing', []).append(row)\n",
        "            elif row[attribute] <= thresh:\n",
        "                parts['le'].append(row)\n",
        "            else:\n",
        "                parts['gt'].append(row)\n",
        "        return parts, thresh\n",
        "    else:\n",
        "        parts = defaultdict(list)\n",
        "        for row in dataset:\n",
        "            val = row.get(attribute, 'missing')\n",
        "            parts[val].append(row)\n",
        "        return dict(parts), None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(dataset, attribute, target_attribute):\n",
        "    base_entropy = entropy([row[target_attribute] for row in dataset])\n",
        "    partitioned = partition(dataset, attribute)\n",
        "    # partition returns (parts, thresh) for numeric, or (parts, None) for categorical\n",
        "    if isinstance(partitioned, tuple):\n",
        "        parts, _ = partitioned\n",
        "    else:\n",
        "        parts = partitioned\n",
        "    total = len(dataset)\n",
        "    remainder = 0.0\n",
        "    for subset in parts.values():\n",
        "        if len(subset) == 0:\n",
        "            continue\n",
        "        weight = len(subset) / total\n",
        "        remainder += weight * entropy([r[target_attribute] for r in subset])\n",
        "    return base_entropy - remainder\n",
        "\n",
        "def majority_label(dataset, target_attribute):\n",
        "    cnt = Counter([row[target_attribute] for row in dataset])\n",
        "    return cnt.most_common(1)[0][0]\n",
        "\n",
        "# --- ID3 recursive algorithm ---\n",
        "\n",
        "def id3(dataset, attributes, target_attribute, depth=0, max_depth=None, min_samples=1):\n",
        "    # If all examples have same label -> leaf\n",
        "    labels = [row[target_attribute] for row in dataset]\n",
        "    if len(set(labels)) == 1:\n",
        "        return Node(is_leaf=True, prediction=labels[0])\n",
        "\n",
        "    # If no attributes left or other stopping conditions\n",
        "    if not attributes or (max_depth is not None and depth >= max_depth) or len(dataset) <= min_samples:\n",
        "        return Node(is_leaf=True, prediction=majority_label(dataset, target_attribute))\n",
        "\n",
        "    # Choose the best attribute by information gain\n",
        "    best_attr = None\n",
        "    best_gain = -1\n",
        "    best_thresh = None\n",
        "    for attr in attributes:\n",
        "        parts_thresh = partition(dataset, attr)\n",
        "        if not parts_thresh:\n",
        "            continue\n",
        "        if isinstance(parts_thresh, tuple):\n",
        "            parts, thresh = parts_thresh\n",
        "        else:\n",
        "            parts, thresh = parts_thresh, None\n",
        "        gain = information_gain(dataset, attr, target_attribute)\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_attr = attr\n",
        "            best_thresh = thresh\n",
        "\n",
        "    if best_attr is None:\n",
        "        return Node(is_leaf=True, prediction=majority_label(dataset, target_attribute))\n",
        "\n",
        "    node = Node(attribute=best_attr, threshold=best_thresh)\n",
        "\n",
        "    parts, _ = partition(dataset, best_attr) if isinstance(partition(dataset, best_attr), tuple) else (partition(dataset, best_attr), None)\n",
        "\n",
        "    # Remove chosen attribute for subsequent splits if it's categorical\n",
        "    remaining_attrs = [a for a in attributes if a != best_attr]\n",
        "\n",
        "    for key, subset in parts.items():\n",
        "        if not subset:\n",
        "            node.add_child(key, Node(is_leaf=True, prediction=majority_label(dataset, target_attribute)))\n",
        "        else:\n",
        "            # For numeric, keep attribute in attributes list (we can split again on numeric with new threshold)\n",
        "            child = id3(subset, remaining_attrs, target_attribute, depth+1, max_depth, min_samples)\n",
        "            node.add_child(key, child)\n",
        "\n",
        "    return node\n",
        "\n"
      ],
      "metadata": {
        "id": "Qq-JTT2GSvCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(node, row):\n",
        "    while not node.is_leaf:\n",
        "        attr = node.attribute\n",
        "        if node.threshold is not None:\n",
        "            # numeric split\n",
        "            val = row.get(attr, None)\n",
        "            if val is None:\n",
        "                # missing: try 'missing' child, else majority branch\n",
        "                if 'missing' in node.children:\n",
        "                    node = node.children['missing']\n",
        "                    continue\n",
        "                # fallthrough: pick larger child\n",
        "                node = node.children.get('le') or node.children.get('gt')\n",
        "                continue\n",
        "            branch = 'le' if val <= node.threshold else 'gt'\n",
        "            node = node.children.get(branch, Node(is_leaf=True, prediction=None))\n",
        "        else:\n",
        "            val = row.get(attr, 'missing')\n",
        "            node = node.children.get(val)\n",
        "            if node is None:\n",
        "                # unseen attribute value: can't traverse; return None\n",
        "                return None\n",
        "    return node.prediction\n",
        "\n",
        "# --- Pretty-print tree ---\n",
        "\n",
        "def print_tree(node, indent=\"\"):\n",
        "    if node.is_leaf:\n",
        "        print(indent + \"-> Predict:\", node.prediction)\n",
        "        return\n",
        "    if node.threshold is not None:\n",
        "        print(indent + f\"[{node.attribute} <= {node.threshold}]\")\n",
        "        if 'le' in node.children:\n",
        "            print(indent + \"  (<=) \")\n",
        "            print_tree(node.children['le'], indent + \"    \")\n",
        "        if 'gt' in node.children:\n",
        "            print(indent + \"  (>) \")\n",
        "            print_tree(node.children['gt'], indent + \"    \")\n",
        "        if 'missing' in node.children:\n",
        "            print(indent + \"  (missing) \")\n",
        "            print_tree(node.children['missing'], indent + \"    \")\n",
        "    else:\n",
        "        print(indent + f\"[{node.attribute}]\")\n",
        "        for val, child in node.children.items():\n",
        "            print(indent + f\"  (== {val})\")\n",
        "            print_tree(child, indent + \"    \")\n",
        "\n",
        "# --- Example usage ---\n",
        "\n",
        "def main():\n",
        "    # Example dataset: simplified 'Play Tennis' (categorical + numeric example)\n",
        "    # Each row is a dict of attributes; target label 'Play'\n",
        "    dataset = [\n",
        "        {'Outlook': 'Sunny', 'Temperature': 85, 'Humidity': 85, 'Windy': False, 'Play': 'No'},\n",
        "        {'Outlook': 'Sunny', 'Temperature': 80, 'Humidity': 90, 'Windy': True, 'Play': 'No'},\n",
        "        {'Outlook': 'Overcast', 'Temperature': 83, 'Humidity': 78, 'Windy': False, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Rain', 'Temperature': 70, 'Humidity': 96, 'Windy': False, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Rain', 'Temperature': 68, 'Humidity': 80, 'Windy': False, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Rain', 'Temperature': 65, 'Humidity': 70, 'Windy': True, 'Play': 'No'},\n",
        "        {'Outlook': 'Overcast', 'Temperature': 64, 'Humidity': 65, 'Windy': True, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Sunny', 'Temperature': 72, 'Humidity': 95, 'Windy': False, 'Play': 'No'},\n",
        "        {'Outlook': 'Sunny', 'Temperature': 69, 'Humidity': 70, 'Windy': False, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Rain', 'Temperature': 75, 'Humidity': 80, 'Windy': False, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Sunny', 'Temperature': 75, 'Humidity': 70, 'Windy': True, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Overcast', 'Temperature': 72, 'Humidity': 90, 'Windy': True, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Overcast', 'Temperature': 81, 'Humidity': 75, 'Windy': False, 'Play': 'Yes'},\n",
        "        {'Outlook': 'Rain', 'Temperature': 71, 'Humidity': 80, 'Windy': True, 'Play': 'No'},\n",
        "    ]\n",
        "\n",
        "    attributes = ['Outlook', 'Temperature', 'Humidity', 'Windy']\n",
        "    target = 'Play'\n",
        "\n",
        "    tree = id3(dataset, attributes, target)\n",
        "    print(\"Constructed decision tree:\\n\")\n",
        "    print_tree(tree)\n",
        "\n",
        "    # Test prediction\n",
        "    test = {'Outlook': 'Sunny', 'Temperature': 66, 'Humidity': 90, 'Windy': True}\n",
        "    pred = predict(tree, test)\n",
        "    print('\\nTest row:', test)\n",
        "    print('Predicted label:', pred)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxw-_I9WS3J3",
        "outputId": "f50cea39-f499-4e1d-e924-056152824144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructed decision tree:\n",
            "\n",
            "[Outlook]\n",
            "  (== Sunny)\n",
            "    [Temperature <= 75]\n",
            "      (<=) \n",
            "        [Humidity <= 70]\n",
            "          (<=) \n",
            "            -> Predict: Yes\n",
            "          (>) \n",
            "            -> Predict: No\n",
            "      (>) \n",
            "        -> Predict: No\n",
            "  (== Overcast)\n",
            "    -> Predict: Yes\n",
            "  (== Rain)\n",
            "    [Windy <= False]\n",
            "      (<=) \n",
            "        -> Predict: Yes\n",
            "      (>) \n",
            "        -> Predict: No\n",
            "\n",
            "Test row: {'Outlook': 'Sunny', 'Temperature': 66, 'Humidity': 90, 'Windy': True}\n",
            "Predicted label: No\n"
          ]
        }
      ]
    }
  ]
}